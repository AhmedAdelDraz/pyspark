{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9da32d6",
   "metadata": {
    "id": "c9da32d6"
   },
   "source": [
    "# NLP Using PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8326ba88",
   "metadata": {
    "id": "8326ba88"
   },
   "source": [
    "## Objective:\n",
    "- The objective from this project is to create a <b>Spam filter using NaiveBayes classifier</b>.\n",
    "- It is required to obtain <b>f1_scored > 0.9</b>.\n",
    "- We'll use a dataset from UCI Repository. SMS Spam Detection:<br>\n",
    "https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31bc851",
   "metadata": {
    "id": "e31bc851"
   },
   "source": [
    "### Create a spark session and import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcf86e46",
   "metadata": {
    "id": "dcf86e46"
   },
   "outputs": [],
   "source": [
    "import findspark \n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as pyfunc\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d00718f",
   "metadata": {
    "id": "2d00718f"
   },
   "source": [
    "### Read the data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29914cf1",
   "metadata": {
    "id": "29914cf1"
   },
   "outputs": [],
   "source": [
    "df = spark.read.format('csv').option('sep','\\t').load('SMSSpamCollection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eabb78dc-025e-4d86-938b-41cef325a97b",
   "metadata": {
    "id": "eabb78dc-025e-4d86-938b-41cef325a97b",
    "outputId": "eb66e88c-e2a3-4b15-fba7-781750f3eab9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "| _c0|                 _c1|\n",
      "+----+--------------------+\n",
      "| ham|Go until jurong p...|\n",
      "| ham|Ok lar... Joking ...|\n",
      "|spam|Free entry in 2 a...|\n",
      "| ham|U dun say so earl...|\n",
      "| ham|Nah I don't think...|\n",
      "|spam|FreeMsg Hey there...|\n",
      "| ham|Even my brother i...|\n",
      "| ham|As per your reque...|\n",
      "|spam|WINNER!! As a val...|\n",
      "|spam|Had your mobile 1...|\n",
      "+----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182cd7f6",
   "metadata": {
    "id": "182cd7f6"
   },
   "source": [
    "### Print the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b52706b9",
   "metadata": {
    "id": "b52706b9",
    "outputId": "6b453333-638b-400d-bb15-7e4cde896ae9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b90cce7",
   "metadata": {
    "id": "2b90cce7"
   },
   "source": [
    "### Rename the first column to 'class' and second column to 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf39446-72d1-4449-b2cb-5ed12914531e",
   "metadata": {
    "id": "0bf39446-72d1-4449-b2cb-5ed12914531e"
   },
   "outputs": [],
   "source": [
    "df2 = df.withColumnRenamed(\"_c0\",\"class\").withColumnRenamed(\"_c1\",\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3799345f-00a3-417a-b406-27dccd81510a",
   "metadata": {
    "id": "3799345f-00a3-417a-b406-27dccd81510a",
    "outputId": "4d703d77-86ac-43fa-a040-24dcb8e8ebc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- class: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e798d0",
   "metadata": {
    "id": "a3e798d0"
   },
   "source": [
    "### Show the first 10 rows from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8cf0ced-e738-42cb-91b6-a1341873aee4",
   "metadata": {
    "id": "b8cf0ced-e738-42cb-91b6-a1341873aee4",
    "outputId": "5d06bd3a-b3b5-48f7-d638-c27e88a80218"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|class|                text|\n",
      "+-----+--------------------+\n",
      "|  ham|Go until jurong p...|\n",
      "|  ham|Ok lar... Joking ...|\n",
      "| spam|Free entry in 2 a...|\n",
      "|  ham|U dun say so earl...|\n",
      "|  ham|Nah I don't think...|\n",
      "| spam|FreeMsg Hey there...|\n",
      "|  ham|Even my brother i...|\n",
      "|  ham|As per your reque...|\n",
      "| spam|WINNER!! As a val...|\n",
      "| spam|Had your mobile 1...|\n",
      "+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe744a9",
   "metadata": {
    "id": "2fe744a9"
   },
   "source": [
    "## Clean and Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d693167",
   "metadata": {
    "id": "4d693167"
   },
   "source": [
    "### Create a new feature column contains the length of the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5424a0cb",
   "metadata": {
    "id": "5424a0cb"
   },
   "outputs": [],
   "source": [
    "df3 = df2.withColumn(\"length\", pyfunc.length(df2.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ea2de6",
   "metadata": {
    "id": "78ea2de6"
   },
   "source": [
    "### Show the new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04c67c53",
   "metadata": {
    "id": "04c67c53",
    "outputId": "54aecebd-6580-443c-8448-8306039abcee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+\n",
      "|class|                text|length|\n",
      "+-----+--------------------+------+\n",
      "|  ham|Go until jurong p...|   111|\n",
      "|  ham|Ok lar... Joking ...|    29|\n",
      "| spam|Free entry in 2 a...|   155|\n",
      "|  ham|U dun say so earl...|    49|\n",
      "|  ham|Nah I don't think...|    61|\n",
      "| spam|FreeMsg Hey there...|   147|\n",
      "|  ham|Even my brother i...|    77|\n",
      "|  ham|As per your reque...|   160|\n",
      "| spam|WINNER!! As a val...|   157|\n",
      "| spam|Had your mobile 1...|   154|\n",
      "|  ham|I'm gonna be home...|   109|\n",
      "| spam|SIX chances to wi...|   136|\n",
      "| spam|URGENT! You have ...|   155|\n",
      "|  ham|I've been searchi...|   196|\n",
      "|  ham|I HAVE A DATE ON ...|    35|\n",
      "| spam|XXXMobileMovieClu...|   149|\n",
      "|  ham|Oh k...i'm watchi...|    26|\n",
      "|  ham|Eh u remember how...|    81|\n",
      "|  ham|Fine if thatÂ’s th...|    56|\n",
      "| spam|England v Macedon...|   155|\n",
      "+-----+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692e37a6",
   "metadata": {
    "id": "692e37a6"
   },
   "source": [
    "### Get the average text length for each class (give alias name to the average length column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c32727d",
   "metadata": {
    "id": "5c32727d",
    "outputId": "f2656533-64c2-4841-f9c7-992972da16b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|class|      avg(length)|\n",
      "+-----+-----------------+\n",
      "|  ham|71.45431945307645|\n",
      "| spam|138.6706827309237|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.groupBy('class').agg({'length':'avg'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e101af",
   "metadata": {
    "id": "d5e101af"
   },
   "source": [
    "## Feature Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838ad9dd",
   "metadata": {
    "id": "838ad9dd"
   },
   "source": [
    "### In this part you transform you raw text in to tf_idf model :\n",
    "- For more information about TF-IDF check the following link: <br>\n",
    "https://en.wikipedia.org/wiki/Tf%E2%80%93idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225067d5",
   "metadata": {
    "id": "225067d5"
   },
   "source": [
    "### Perform the following steps to obtain TF-IDF:\n",
    "1. Import the required transformers/estimators for the subsequent steps.\n",
    "2. Create a <b>Tokenizer</b> from the text column.\n",
    "3. Create a <b>StopWordsRemover</b> to remove the <b>stop words</b> from the column obtained from the <b>Tokenizer</b>.\n",
    "4. Create a <b>CountVectorizer</b> after removing the <b>stop words</b>.\n",
    "5. Create the <b>TF-IDF</b> from the <b>CountVectorizer</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a4eebf8",
   "metadata": {
    "id": "6a4eebf8"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer,StopWordsRemover,CountVectorizer,StringIndexer,VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b82756db",
   "metadata": {
    "id": "b82756db"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol='text',outputCol='tokenized_text')\n",
    "stopwordsremover = StopWordsRemover(inputCol='tokenized_text',outputCol='stop_removed')\n",
    "countvectorizer = CountVectorizer(inputCol='stop_removed',outputCol='TF_IDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1527ad65",
   "metadata": {
    "id": "1527ad65"
   },
   "source": [
    "- Convert the <b>class column</b> to index using <b>StringIndexer</b>\n",
    "- Create feature column from the <b>TF-IDF</b> and <b>lenght</b> columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aaf46159",
   "metadata": {
    "id": "aaf46159"
   },
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer(inputCol='class',outputCol='class_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad9d4c52",
   "metadata": {
    "id": "ad9d4c52"
   },
   "outputs": [],
   "source": [
    "vectorassembler = VectorAssembler(inputCols=['TF_IDF','length'],outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9775d494",
   "metadata": {
    "id": "9775d494"
   },
   "source": [
    "## The Model\n",
    "- Create a <b>NaiveBayes</b> classifier with the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57af0d5d",
   "metadata": {
    "id": "57af0d5d"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "naivebayes = NaiveBayes(featuresCol='features',labelCol='class_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc14de63",
   "metadata": {
    "id": "dc14de63"
   },
   "source": [
    "## Pipeline\n",
    "### Create a pipeline model contains all the steps starting from the Tokenizer to the NaiveBays classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ee0d1ca",
   "metadata": {
    "id": "8ee0d1ca"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f82bab0",
   "metadata": {
    "id": "7f82bab0"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[tokenizer,stopwordsremover,countvectorizer,stringIndexer,\\\n",
    "                           vectorassembler,naivebayes])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d7efbe",
   "metadata": {
    "id": "f5d7efbe"
   },
   "source": [
    "### Split your data to trian and test data with ratios 0.7 and 0.3 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2843d997",
   "metadata": {
    "id": "2843d997"
   },
   "outputs": [],
   "source": [
    "train, test = df3.randomSplit([0.7,0.3],seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcea576",
   "metadata": {
    "id": "8bcea576"
   },
   "source": [
    "### Fit your Pipeline model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c5d4681",
   "metadata": {
    "id": "3c5d4681"
   },
   "outputs": [],
   "source": [
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228a3eb1",
   "metadata": {
    "id": "228a3eb1"
   },
   "source": [
    "### Perform predictions on tests dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14f4aab5",
   "metadata": {
    "id": "14f4aab5"
   },
   "outputs": [],
   "source": [
    "predDF = model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce2885f",
   "metadata": {
    "id": "bce2885f"
   },
   "source": [
    "### Print the schema of the prediction dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "377b3fd8-c9ef-4a21-905c-d359b6d4aa2f",
   "metadata": {
    "id": "377b3fd8-c9ef-4a21-905c-d359b6d4aa2f",
    "outputId": "e177720b-b9ee-4fbe-b70f-92fa74aab770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- class: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- length: integer (nullable = true)\n",
      " |-- tokenized_text: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- stop_removed: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- TF_IDF: vector (nullable = true)\n",
      " |-- class_index: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f27055",
   "metadata": {
    "id": "57f27055"
   },
   "source": [
    "## Model Evaluation\n",
    "- Use <b>MulticlassClassificationEvaluator</b> to calculate the <b>f1_score</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be706565",
   "metadata": {
    "id": "be706565",
    "outputId": "2e1924b4-00e2-4897-80bb-2b363ea9d4a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score is: 0.9723827056612554\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator \n",
    "metric = MulticlassClassificationEvaluator(predictionCol='prediction',\n",
    "                                           labelCol='class_index',\n",
    "                                           metricName='f1')\n",
    "f1_score = metric.evaluate(predDF)\n",
    "print(f'f1_score is: {f1_score}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Spark and Python for Big Data Final Exam-Branches.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
